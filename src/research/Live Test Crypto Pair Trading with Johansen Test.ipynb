{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IoffContext at 0x7fe104ae9250>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from stats_arb.tests import adf_test, kpss_test, cal_half_life, pp_test\n",
    "from datetime import datetime, timedelta\n",
    "from ta.volatility import BollingerBands\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6) # (w, h)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_BASE = 'https://fapi.binance.com/fapi/v1/'\n",
    "# DATA_PATH = '/mnt/c/Users/vmodg/source/repos/BeanRepos/crypto-pair-trading/data/'\n",
    "DATA_PATH = '/mnt/d/Working/PersonalProjects/Trading/trading-agent/crypto-pair-trading/data/crypto/'\n",
    "TIMEFRAME = '1d'\n",
    "lookback = 365\n",
    "\n",
    "TIMEFRAME = '1h'\n",
    "lookback = 30*4\n",
    "\n",
    "TIMEFRAME = '15m'\n",
    "lookback = 30*4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "LABELS = [\n",
    "    'open_time',\n",
    "    'open',\n",
    "    'high',\n",
    "    'low',\n",
    "    'close',\n",
    "    'volume',\n",
    "    'close_time',\n",
    "    'quote_asset_volume',\n",
    "    'number_of_trades',\n",
    "    'taker_buy_base_asset_volume',\n",
    "    'taker_buy_quote_asset_volume',\n",
    "    'ignore'\n",
    "]\n",
    "\n",
    "DROP_COLUMNS=[\n",
    "    'close_time',\n",
    "    'quote_asset_volume',\n",
    "    'number_of_trades',\n",
    "    'taker_buy_base_asset_volume',\n",
    "    'taker_buy_quote_asset_volume',\n",
    "    'ignore'\n",
    "]\n",
    "\n",
    "\n",
    "def get_batch(symbol, interval='1m', start_time=0, limit=400):\n",
    "    \"\"\"Use a GET request to retrieve a batch of candlesticks. Process the JSON into a pandas\n",
    "    dataframe and return it. If not successful, return an empty dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "        'symbol': symbol,\n",
    "        'interval': interval,\n",
    "        'startTime': start_time,\n",
    "        'limit': limit\n",
    "    }\n",
    "    try:\n",
    "        # timeout should also be given as a parameter to the function\n",
    "        response = requests.get(f'{API_BASE}klines', params, timeout=30)\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print('Connection error, Cooling down for 5 mins...')\n",
    "        time.sleep(15)\n",
    "        return get_batch(symbol, interval, start_time, limit)\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        print('Timeout, Cooling down for 5 min...')\n",
    "        time.sleep(15)\n",
    "        return get_batch(symbol, interval, start_time, limit)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return pd.DataFrame(response.json(), columns=LABELS)\n",
    "    \n",
    "    print(f'Got erroneous response back {symbol}: {response}. {response.text}')\n",
    "    return pd.DataFrame([])\n",
    "\n",
    "\n",
    "def get_candles(base, quote, start_date: datetime, end_date=None, interval='1m'):\n",
    "    batches = []\n",
    "\n",
    "    if end_date is None:\n",
    "        end_date = datetime.utcnow()\n",
    "\n",
    "    last_timestamp = int(start_date.timestamp()) * 1000\n",
    "    # gather all candlesticks available, starting from the last timestamp loaded from disk or 0\n",
    "    # stop if the timestamp that comes back from the api is the same as the last one\n",
    "    previous_timestamp = None\n",
    "\n",
    "    while previous_timestamp != last_timestamp:\n",
    "        # stop if we reached data from today\n",
    "        if datetime.fromtimestamp(last_timestamp / 1000) >= end_date:\n",
    "            break\n",
    "\n",
    "        previous_timestamp = last_timestamp\n",
    "\n",
    "        new_batch = get_batch(\n",
    "            symbol=base + quote,\n",
    "            interval=interval,\n",
    "            start_time=last_timestamp\n",
    "        )\n",
    "\n",
    "        # requesting candles from the future returns empty\n",
    "        # also stop in case response code was not 200\n",
    "        if new_batch.empty:\n",
    "            break\n",
    "\n",
    "        last_timestamp = new_batch['open_time'].max()\n",
    "\n",
    "        # sometimes no new trades took place yet on date.today();\n",
    "        # in this case the batch is nothing new\n",
    "        if previous_timestamp == last_timestamp:\n",
    "            break\n",
    "\n",
    "        batches.append(new_batch)\n",
    "        last_datetime = datetime.fromtimestamp(last_timestamp / 1000)\n",
    "\n",
    "        covering_spaces = 20 * ' '\n",
    "        print(datetime.now(), base, quote, interval, str(last_datetime) + covering_spaces, end='\\r', flush=True)\n",
    "\n",
    "    if len(batches) > 0:\n",
    "        # write clean version of csv to parquet\n",
    "        df = pd.concat(batches, ignore_index=True)\n",
    "        df.drop(columns=DROP_COLUMNS, inplace=True)\n",
    "        df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')\n",
    "        df.set_index('open_time', inplace=True)\n",
    "        df = df[~df.index.duplicated(keep='first')]\n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# url = \"https://fapi.binance.com/fapi/v1/exchangeInfo\"\n",
    "\n",
    "# payload={}\n",
    "# headers = {}\n",
    "\n",
    "# response = requests.request(\"GET\", url, headers=headers, data=payload).json()\n",
    "\n",
    "# symbols = [s['symbol'] for s in response['symbols'] if s['contractType'] == 'PERPETUAL' and s['quoteAsset'] == 'USDT']\n",
    "# # symbols[100:]\n",
    "# symbols = symbols[:50]\n",
    "# len(symbols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-12 15:11:21.455341 NEAR USDT 15m 2023-05-12 15:00:00                     \r"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/d/Working/PersonalProjects/Trading/trading-agent/crypto-pair-trading/data/crypto//15m/EOS-USDT.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_554/3151579192.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msymbol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{DATA_PATH}/{TIMEFRAME}/{symbol}-USDT.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'open_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'open_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# print('start time', df.index[-1].to_pydatetime())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/trade/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/trade/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/trade/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/trade/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/trade/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/trade/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/trade/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/trade/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n\u001b[1;32m    708\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/d/Working/PersonalProjects/Trading/trading-agent/crypto-pair-trading/data/crypto//15m/EOS-USDT.csv'"
     ]
    }
   ],
   "source": [
    "# symbols = pd.read_csv(f'/mnt/d/Working/PersonalProjects/Trading/trading-agent/crypto-pair-trading/data/symbols.csv')['symbol'].values.tolist()\n",
    "symbols = ['BTCUSDT',\n",
    "'ETHUSDT',\n",
    "'XRPUSDT',\n",
    "'LTCUSDT',\n",
    "'ETCUSDT',\n",
    "'LINKUSDT',\n",
    "'XLMUSDT',\n",
    "'ADAUSDT',\n",
    "'BNBUSDT',\n",
    "'ATOMUSDT',\n",
    "'ALGOUSDT',\n",
    "'DOTUSDT',\n",
    "'SOLUSDT',\n",
    "'AVAXUSDT',\n",
    "'MATICUSDT',\n",
    "'XMRUSDT',\n",
    "'NEARUSDT',\n",
    "'EOSUSDT',\n",
    "'NEOUSDT',\n",
    "'UNIUSDT']\n",
    "symbols = [s.replace('USDT', '') for s in symbols]\n",
    "\n",
    "data = []\n",
    "start_time = datetime.utcnow() - timedelta(days=lookback)\n",
    "\n",
    "for symbol in symbols:\n",
    "    df = pd.read_csv(f'{DATA_PATH}/{TIMEFRAME}/{symbol}-USDT.csv', parse_dates=['open_time'], index_col=['open_time'])\n",
    "    df = df[df.index >= start_time].copy()\n",
    "    # print('start time', df.index[-1].to_pydatetime())\n",
    "\n",
    "    df1 = get_candles(\n",
    "        base=symbol, \n",
    "        quote='USDT', \n",
    "        start_date=df.index[-1].to_pydatetime(),\n",
    "        # end_date=datetime.now() - timedelta(days=15),\n",
    "        interval=TIMEFRAME\n",
    "    )\n",
    "    if df1 is not None:\n",
    "        df = pd.concat([df, df1])\n",
    "        df = df[~df.index.duplicated(keep='first')]\n",
    "\n",
    "    df.rename(columns={'close': symbol}, inplace=True)\n",
    "    # the data is too long, just limit to recent period\n",
    "    log = np.log(df[symbol].astype(np.float32))\n",
    "    data.append(log)\n",
    "\n",
    "df = pd.concat(data, axis=1)\n",
    "df = df.dropna(axis=1, how='all')\n",
    "# df.dropna(inplace=True, how='any')\n",
    "\n",
    "# our of sample\n",
    "# df = df[df.index <= datetime.now() - timedelta(days=15)].copy()\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1\n",
    "COINTEGRATION_CONFIDENCE_LEVEL = 90\n",
    "\n",
    "# the 90%, 95%, and 99% confidence levels for the trace statistic and maximum \n",
    "# eigenvalue statistic are stored in the first, second, and third column of \n",
    "# cvt and cvm, respectively\n",
    "confidence_level_cols = {\n",
    "    90: 0,\n",
    "    95: 1,\n",
    "    99: 2\n",
    "}\n",
    "confidence_level_col = confidence_level_cols[COINTEGRATION_CONFIDENCE_LEVEL]\n",
    "\n",
    "\n",
    "def test_johansen(symbol_pairs):\n",
    "    df_t = df[symbol_pairs].copy()\n",
    "    df_t.dropna(inplace=True)\n",
    "\n",
    "    # The second and third parameters indicate constant term, with a lag of 1. \n",
    "    result = coint_johansen(df_t, 0, p)\n",
    "\n",
    "    trace_crit_value = result.cvt[:, confidence_level_col]\n",
    "    eigen_crit_value = result.cvm[:, confidence_level_col]\n",
    "#     print(\"trace_crit_value\",trace_crit_value)\n",
    "#     print(\"eigen_crit_value\",eigen_crit_value)\n",
    "#     print(\"lr1\",result.lr1)\n",
    "#     print(\"lr2\",result.lr2)\n",
    "\n",
    "    # The trace statistic and maximum eigenvalue statistic are stored in lr1 and lr2;\n",
    "    # see if they exceeded the confidence threshold\n",
    "    if np.all(result.lr1 >= trace_crit_value) and np.all(result.lr2 >= eigen_crit_value):\n",
    "        # print(f\"{symbol_pairs} are cointegrated\")\n",
    "        # The first i.e. leftmost column of eigenvectors matrix, result.evec, contains the best weights.\n",
    "        v1= result.evec[:,0:1]\n",
    "        hr=v1/-v1[1] #to get the hedge ratio divide the best_eigenvector by the negative of the second component of best_eigenvector\n",
    "        #the regression will be: close of symbList[1] = hr[0]*close of symbList[0] + error\n",
    "        #where the beta of the regression is hr[0], also known as the hedge ratio, and\n",
    "        #the error of the regression is the mean reverting residual signal that you need to predict, it is also known as the \"spread\"\n",
    "        #the spread = close of symbList[1] - hr[0]*close of symbList[0] or alternatively (the same thing):\n",
    "        #do a regression with close of symbList[0] as x and lose of symbList[1] as y, and take the residuals of the regression to be the spread.\n",
    "        coint_pair = dict(hedge_ratio=v1[:, 0])\n",
    "        for i, s in enumerate(symbol_pairs):\n",
    "            coint_pair[f'sid_{i+1}'] = s\n",
    "\n",
    "        cointegrating_pairs.append(coint_pair)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "\n",
    "def calculate_spread(df, coint_df, selected_row, hedge_ratio, nb_symbols=2):\n",
    "    spread = None\n",
    "    for i in range(nb_symbols):\n",
    "        if spread is None:\n",
    "            spread = df[coint_df[f'sid_{i + 1}'].iloc[selected_row]] * hedge_ratio[i]\n",
    "        else:\n",
    "            spread += df[coint_df[f'sid_{i + 1}'].iloc[selected_row]] * hedge_ratio[i]\n",
    "    \n",
    "    spread.dropna(inplace=True)\n",
    "    return spread\n",
    "\n",
    "\n",
    "critical_val = 0.02\n",
    "\n",
    "def find_stationary_portfolio(coint_df):\n",
    "    data = []\n",
    "    for i, _ in coint_df.iterrows():\n",
    "        try:\n",
    "            hedge_ratio = coint_df.iloc[i]['hedge_ratio']\n",
    "            _df = df.copy()\n",
    "            spread = calculate_spread(_df, coint_df, i, hedge_ratio)\n",
    "            p_val = adf_test(spread, verbose=False)\n",
    "            if p_val < critical_val:\n",
    "                half_life = cal_half_life(spread)\n",
    "                pairs_name = coint_df[[col for col in coint_df.columns if 'sid' in col]].iloc[i].values\n",
    "                # print(i, pairs_name, 'is stationary with half life', half_life)\n",
    "                # print(' ')\n",
    "                data.append({\n",
    "                    'i': i,\n",
    "                    'pairs': pairs_name,\n",
    "                    'half_life': half_life\n",
    "                })\n",
    "        except:\n",
    "            print(coint_df.iloc[i])\n",
    "            # traceback.print_exc()\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# find_stationary_portfolio(coint_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hedge_ratio</th>\n",
       "      <th>sid_1</th>\n",
       "      <th>sid_2</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6.345277579317586, 10.48442732616329]</td>\n",
       "      <td>BTC</td>\n",
       "      <td>ETC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.7197864501156175, 15.753997367923263]</td>\n",
       "      <td>BTC</td>\n",
       "      <td>LINK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[6.031906957752859, -29.10429389108478]</td>\n",
       "      <td>BTC</td>\n",
       "      <td>BNB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[6.7720729512579165, -28.440406144780003]</td>\n",
       "      <td>ETH</td>\n",
       "      <td>BNB</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[12.042047454300542, -23.52468744768704]</td>\n",
       "      <td>LTC</td>\n",
       "      <td>LINK</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 hedge_ratio sid_1 sid_2  i\n",
       "0     [6.345277579317586, 10.48442732616329]   BTC   ETC  0\n",
       "1   [0.7197864501156175, 15.753997367923263]   BTC  LINK  1\n",
       "2    [6.031906957752859, -29.10429389108478]   BTC   BNB  2\n",
       "3  [6.7720729512579165, -28.440406144780003]   ETH   BNB  3\n",
       "4   [12.042047454300542, -23.52468744768704]   LTC  LINK  4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import itertools as it\n",
    "\n",
    "nb_symbols = 2\n",
    "cointegrating_pairs = []\n",
    "\n",
    "#get symbol pairs\n",
    "pairs = list(it.combinations(symbols, nb_symbols))\n",
    "\n",
    "for pair in pairs:\n",
    "    try:\n",
    "        test_johansen(list(pair))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "coint_df = pd.DataFrame(cointegrating_pairs)\n",
    "coint_df['i'] = coint_df.index\n",
    "coint_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coint_df.to_csv(f'coint_df_{TIMEFRAME}.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "stationary_df = find_stationary_portfolio(coint_df)\n",
    "stationary_df = pd.merge(stationary_df, coint_df, on='i')\n",
    "stationary_df.dropna(inplace=True)\n",
    "stationary_df['i'] = stationary_df.i.astype('int64')\n",
    "stationary_df['half_life'] = stationary_df.half_life.astype('int64')\n",
    "if len(stationary_df) > 0:\n",
    "    stationary_df.sort_values(by=['half_life'], inplace=True)\n",
    "# stationary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_df.to_csv(f'stationary_df_{TIMEFRAME}.csv', index=False)\n",
    "# stationary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>pairs</th>\n",
       "      <th>half_life</th>\n",
       "      <th>hedge_ratio</th>\n",
       "      <th>sid_1</th>\n",
       "      <th>sid_2</th>\n",
       "      <th>hdiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>[ETC, SOL]</td>\n",
       "      <td>60</td>\n",
       "      <td>[16.510708258437667, -17.36754479434316]</td>\n",
       "      <td>ETC</td>\n",
       "      <td>SOL</td>\n",
       "      <td>-0.856837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>39</td>\n",
       "      <td>[SOL, XMR]</td>\n",
       "      <td>62</td>\n",
       "      <td>[13.923358109917105, -17.41760029211751]</td>\n",
       "      <td>SOL</td>\n",
       "      <td>XMR</td>\n",
       "      <td>-3.494242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>[ETC, DOT]</td>\n",
       "      <td>74</td>\n",
       "      <td>[22.49037311164565, -20.678270069335337]</td>\n",
       "      <td>ETC</td>\n",
       "      <td>DOT</td>\n",
       "      <td>1.812103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>[ETC, XMR]</td>\n",
       "      <td>76</td>\n",
       "      <td>[19.71549226385198, -22.94308047390305]</td>\n",
       "      <td>ETC</td>\n",
       "      <td>XMR</td>\n",
       "      <td>-3.227588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     i       pairs  half_life                               hedge_ratio sid_1  \\\n",
       "7    9  [ETC, SOL]         60  [16.510708258437667, -17.36754479434316]   ETC   \n",
       "30  39  [SOL, XMR]         62  [13.923358109917105, -17.41760029211751]   SOL   \n",
       "6    8  [ETC, DOT]         74  [22.49037311164565, -20.678270069335337]   ETC   \n",
       "9   11  [ETC, XMR]         76   [19.71549226385198, -22.94308047390305]   ETC   \n",
       "\n",
       "   sid_2     hdiff  \n",
       "7    SOL -0.856837  \n",
       "30   XMR -3.494242  \n",
       "6    DOT  1.812103  \n",
       "9    XMR -3.227588  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignored_symbols = ['LTC', 'AVAX', 'ETC', 'XMR']\n",
    "ignored_symbols= []\n",
    "mask = ~(stationary_df['sid_1'].isin(ignored_symbols) | stationary_df['sid_2'].isin(ignored_symbols))\n",
    "filtered_df = stationary_df[mask]\n",
    "filtered_df['hdiff'] = filtered_df['hedge_ratio'].apply(lambda x: np.sum(x))\n",
    "filtered_df.query('abs(hdiff) <= 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "c276c0ee69ef566ef6a4194053af484cf7322cd6b46c4188dcfdf12ebbe5b30c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
